---
title: "p1_continua_alvaro"
author: "Alvaro de la Flor Bonilla"
date: "16/3/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Random Forest

En primer lugar, cargamos los datos con los que trabajaremos durante todo el proyecto.

```{r}
library(tidyverse)
data_raw <- read_csv('train.csv')
data_raw # str(data_raw) , glimpse(data_raw)
```

El siguiente paso, antes de comenzar consistirá en realizar un preprocesamiento de los datos. Para ver estos podemos utilizar:

```{r}
library(funModeling)
df_status(data_raw)
```

Filtramos los valores

```{r}
status <- df_status(data_raw)

## columnas con NAs
na_cols <- status %>%
  filter(p_na > 70) %>%
  select(variable)
## columnas con valores diferentes
dif_cols <- status %>%
  filter(unique > 0.8 * nrow(data_raw)) %>%
  select(variable)

## eliminar columnas
remove_cols <- bind_rows(
  list(na_cols, dif_cols)
)
data_reduced <- data_raw %>%
  select(-one_of(remove_cols$variable))

status2 <- df_status(data_reduced)
```

Tal y como vimos en la práctica, también tendremos que realizar los siguientes pasos:

-   Codificación de variables: *Survived* = {'Yes', 'No'}, *Pclass* = <tt>factor</tt>
-   Discretización de variables numéricas: *Fare_Interval* = {'More.than.30', 'Between.20.30', 'Between.10.20', 'Less.than.10'}
-   Selección de variables: solo se consideran para la predicción: *Survived* (variable objetivo), *Pclass*, *Sex*, *Fare_Interval*

```{r}
library(caret)
data <-
  data_raw %>%
  mutate(Survived = as.factor(ifelse(Survived == 1, 'Yes', 'No'))) %>%
  mutate(Pclass = as.factor(Pclass)) %>%
  mutate(Fare_Interval = as.factor(
    case_when(
      Fare >= 30 ~ 'More.than.30',
      Fare >= 20 & Fare < 30 ~ 'Between.20.30',
      Fare < 20 & Fare >= 10 ~ 'Between.10.20',
      Fare < 10 ~ 'Less.than.10'))) %>%
  select(Survived, Pclass, Sex, Fare_Interval)

data
```

# 1. Aprendizaje de un modelo de clasificación utilizando 'Random Forest' (lo llamaremos modelo_rf1)

## Parámetros del algoritmo de aprendizaje

En esta primera versión no vamos a utilizar validación cruzada.

```{r}
rpartCtrl1 <- trainControl(classProbs = TRUE)
```

## Conjuntos de entrenamiento y validación

Particionamos los datos en un 70% para el test y 30% para la validación.

```{r}
set.seed(0)
trainIndex1 <- createDataPartition(data$Survived, p = .7, list = FALSE)
train1 <- data[trainIndex, ] 
val1   <- data[-trainIndex, ]
```

```{r}
library(pROC)
modelo_rf1 <- train(Survived ~ ., data = train1, method = "rf", metric = "ROC", trControl = rpartCtrl1)
predictionValidationProb1 <- predict(modelo_rf1, val1, type = "prob")
auc1 <- roc(val1$Survived, predictionValidationProb1[["Yes"]], levels = unique(val1[["Survived"]]))
roc_validation1 <- plot.roc(auc1, ylim=c(0,1), type = "S" , print.thres = T, main=paste('Validation AUC 1:', round(auc1$auc[[1]], 2)))
```

# 2. Variación sobre modelo1 utilizando una partición de datos 80-20 y validación cruzada (modelo_rf2)

```{r}
set.seed(0)
trainIndex2 <- createDataPartition(data$Survived, p = .8, list = FALSE)
train2 <- data[trainIndex, ] 
val2   <- data[-trainIndex, ]
```

```{r}
rpartCtrl2 <- trainControl(verboseIter = TRUE, classProbs = TRUE, summaryFunction = twoClassSummary, method = "cv", number = 10)
```

```{r}
library(pROC)
modelo_rf2 <- train(Survived ~ ., data = train2, method = "rf", metric = "ROC", trControl = rpartCtrl2)
predictionValidationProb2 <- predict(modelo_rf2, val2, type = "prob")
auc2 <- roc(val2$Survived, predictionValidationProb2[["Yes"]], levels = unique(val2[["Survived"]]))
roc_validation2 <- plot.roc(auc2, ylim=c(0,1), type = "S" , print.thres = T, main=paste('Validation AUC 2:', round(auc2$auc[[1]], 2)))
```

# Comparación y selección del mejor modelo en modelo_rf1, modelo_rf2 términos de precisión y AUC (modelo_rf)

```{r}
roc.test(roc_validation1, roc_validation2)
plot.roc(auc1, type = "S", col="#1c61b6") #Azul
lines.roc(auc2, type = "S", col="#008600") #Verde
```
```{r}
predict1 <- predict(modelo_rf1, val1, type = "raw")
predict2 <- predict(modelo_rf2, val2, type = "raw")
cm_train1 <- confusionMatrix(predict1, val1[["Survived"]])
cm_train2 <- confusionMatrix(predict2, val2[["Survived"]])
cm_train1
cm_train2
```

