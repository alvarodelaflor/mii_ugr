library(readxl)
twitter_fakenews_USElections_2016 <- read_excel("~/Repositorios auxiliares/sige2021/prácticas/seminarios/seminario 2/fakenews/twitter_fakenews_USElections_2016.xlsx")
View(twitter_fakenews_USElections_2016)
library(tidyverse)
library(readxl)
data_raw <- read_excel('twitter_fakenews_USElections_2016.xlsx', sheet = 1, na = c('UNKNOWN'))
data_raw
library(tidyverse)
library(readxl)
data_raw <- read_excel('twitter_fakenews_USElections_2016.xlsx', sheet = 1, na = c('UNKNOWN'))
data_raw
library(tidyverse)
library(readxl)
data_raw <- read_excel('twitter_fakenews_USElections_2016.xlsx', sheet = 1, na = c('UNKNOWN'))
data_raw
library(tidyverse)
library(readxl)
data_raw <- read_excel('twitter_fakenews_USElections_2016.xlsx', sheet = 1, na = c('UNKNOWN'))
data_raw
Sys.setlocale("LC_ALL","C")  # Locale for date format
data_raw$created_at <- as.POSIXct(data_raw$created_at, tz="GMT", format="%a %b %d %H:%M:%S +0000 %Y")
data_raw
library(funModeling)
df_status(data_raw)
data <- data_raw %>%
filter(retweet_count > 1000) %>%
na.exclude()
ggplot(data) +
geom_histogram(aes(x = is_fake_news, fill = is_fake_news), stat = 'count')
table(data$is_fake_news)
prop.table(table(data$is_fake_news))
ggplot(data) +
geom_histogram(aes(x = is_fake_news, fill = is_fake_news), stat = 'count')
ggplot(data) +
geom_histogram(aes(x = is_fake_news, fill = is_fake_news), stat = 'count')
table(data$is_fake_news)
prop.table(table(data$is_fake_news))
library(scales)
ggplot(data) +
geom_histogram(aes(x = created_at, fill = is_fake_news ))  +
scale_x_datetime(breaks=date_breaks('2 months'), labels = date_format("%b"))
data_extended <-
data %>%
mutate(tweet_text_exclamations = str_count(text, "!")) %>%
mutate(tweet_text_caps = str_count(text, "[A-Z]")) %>%
mutate(tweet_text_digits = str_count(text, "[0-9]")) %>%
mutate(tweet_text_emojis = str_count(text, '[\U{1F300}-\U{1F6FF}]')) %>%
mutate(tweet_text_emoji_flag = str_count(text, '\U{1F1FA}|\U{1F1F8}]'))
library(tidyverse)
library(readxl)
data_raw <- read_excel('twitter_fakenews_USElections_2016.xlsx', sheet = 1, na = c('UNKNOWN'))
data_raw
Sys.setlocale("LC_ALL","C")  # Locale for date format
data_raw$created_at <- as.POSIXct(data_raw$created_at, tz="GMT", format="%a %b %d %H:%M:%S +0000 %Y")
data_raw
library(funModeling)
df_status(data_raw)
data <- data_raw %>%
filter(retweet_count > 1000) %>%
na.exclude()
ggplot(data) +
geom_histogram(aes(x = is_fake_news, fill = is_fake_news), stat = 'count')
table(data$is_fake_news)
prop.table(table(data$is_fake_news))
ggplot(data) +
geom_histogram(aes(x = is_fake_news, fill = is_fake_news), stat = 'count')
library(scales)
ggplot(data) +
geom_histogram(aes(x = created_at, fill = is_fake_news ))  +
scale_x_datetime(breaks=date_breaks('2 months'), labels = date_format("%b"))
data_extended <-
data %>%
mutate(tweet_text_exclamations = str_count(text, "!")) %>%
mutate(tweet_text_caps = str_count(text, "[A-Z]")) %>%
mutate(tweet_text_digits = str_count(text, "[0-9]")) %>%
mutate(tweet_text_emojis = str_count(text, '[\U{1F300}-\U{1F6FF}]')) %>%
mutate(tweet_text_emoji_flag = str_count(text, '\U{1F1FA}|\U{1F1F8}]'))
data_extended <-
data %>%
mutate(tweet_text_exclamations = str_count(text, "!")) %>%
mutate(tweet_text_caps = str_count(text, "[A-Z]")) %>%
mutate(tweet_text_digits = str_count(text, "[0-9]")) %>%
mutate(tweet_text_emojis = str_count(text, '[\U{1F300}-\U{1F6FF}]')) %>%
mutate(tweet_text_emoji_flag = str_count(text, '\U{1F1FA}|\U{1F1F8}]'))
data_extended <-
data %>%
mutate(tweet_text_exclamations = str_count(text, "!")) %>%
mutate(tweet_text_caps = str_count(text, "[A-Z]")) %>%
mutate(tweet_text_digits = str_count(text, "[0-9]")) %>%
mutate(tweet_text_emojis = str_count(text, '[\U{1F300}-\U{1F6FF}]')) %>%
mutate(tweet_text_emoji_flag = str_count(text, '\U{1F1FA}|\U{1F1F8}]'))
data_extended <-
data %>%
mutate(tweet_text_exclamations = str_count(text, "!")) %>%
mutate(tweet_text_caps = str_count(text, "[A-Z]")) %>%
mutate(tweet_text_digits = str_count(text, "[0-9]")) %>%
mutate(tweet_text_emojis = str_count(text, '[\U{1F300}-\U{1F6FF}]')) %>%
mutate(tweet_text_emoji_flag = str_count(text, '\U{1F1FA}|\U{1F1F8}]'))
library(tidyverse)
library(readxl)
data_raw <- read_excel('twitter_fakenews_USElections_2016.xlsx', sheet = 1, na = c('UNKNOWN'))
data_raw
Sys.setlocale("LC_ALL","C")  # Locale for date format
data_raw$created_at <- as.POSIXct(data_raw$created_at, tz="GMT", format="%a %b %d %H:%M:%S +0000 %Y")
data_raw
library(funModeling)
df_status(data_raw)
data <- data_raw %>%
filter(retweet_count > 1000) %>%
na.exclude()
ggplot(data) +
geom_histogram(aes(x = is_fake_news, fill = is_fake_news), stat = 'count')
table(data$is_fake_news)
prop.table(table(data$is_fake_news))
ggplot(data) +
geom_histogram(aes(x = is_fake_news, fill = is_fake_news), stat = 'count')
library(scales)
ggplot(data) +
geom_histogram(aes(x = created_at, fill = is_fake_news ))  +
scale_x_datetime(breaks=date_breaks('2 months'), labels = date_format("%b"))
data_extended <-
data %>%
mutate(tweet_text_exclamations = str_count(text, "!")) %>%
mutate(tweet_text_caps = str_count(text, "[A-Z]")) %>%
mutate(tweet_text_digits = str_count(text, "[0-9]")) %>%
mutate(tweet_text_emojis = str_count(text, '[\U{1F300}-\U{1F6FF}]')) %>%
mutate(tweet_text_emoji_flag = str_count(text, '\U{1F1FA}|\U{1F1F8}]'))
library(tidyverse)
library(readxl)
data_raw <- read_excel('twitter_fakenews_USElections_2016.xlsx', sheet = 1, na = c('UNKNOWN'))
data_raw
Sys.setlocale("LC_ALL","C")  # Locale for date format
data_raw$created_at <- as.POSIXct(data_raw$created_at, tz="GMT", format="%a %b %d %H:%M:%S +0000 %Y")
data_raw
library(funModeling)
df_status(data_raw)
data <- data_raw %>%
filter(retweet_count > 1000) %>%
na.exclude()
ggplot(data) +
geom_histogram(aes(x = is_fake_news, fill = is_fake_news), stat = 'count')
table(data$is_fake_news)
prop.table(table(data$is_fake_news))
ggplot(data) +
geom_histogram(aes(x = is_fake_news, fill = is_fake_news), stat = 'count')
library(scales)
ggplot(data) +
geom_histogram(aes(x = created_at, fill = is_fake_news ))  +
scale_x_datetime(breaks=date_breaks('2 months'), labels = date_format("%b"))
data_extended <-
data %>%
mutate(tweet_text_exclamations = str_count(text, "!")) %>%
mutate(tweet_text_caps = str_count(text, "[A-Z]")) %>%
mutate(tweet_text_digits = str_count(text, "[0-9]")) %>%
mutate(tweet_text_emojis = str_count(text, '[\U{1F300}-\U{1F6FF}]')) %>%
mutate(tweet_text_emoji_flag = str_count(text, '\U{1F1FA}|\U{1F1F8}]'))
ggplot(data_extended) +
geom_density(aes(x=tweet_text_emojis, color=is_fake_news, fill=is_fake_news), alpha = 0.5)  +
scale_x_continuous(trans="log10")
library(tidyverse)
library(readxl)
data_raw <- read_excel('twitter_fakenews_USElections_2016.xlsx', sheet = 1, na = c('UNKNOWN'))
data_raw
Sys.setlocale("LC_ALL","C")  # Locale for date format
data_raw$created_at <- as.POSIXct(data_raw$created_at, tz="GMT", format="%a %b %d %H:%M:%S +0000 %Y")
data_raw
library(funModeling)
df_status(data_raw)
data <- data_raw %>%
filter(retweet_count > 1000) %>%
na.exclude()
ggplot(data) +
geom_histogram(aes(x = is_fake_news, fill = is_fake_news), stat = 'count')
table(data$is_fake_news)
prop.table(table(data$is_fake_news))
ggplot(data) +
geom_histogram(aes(x = is_fake_news, fill = is_fake_news), stat = 'count')
library(scales)
ggplot(data) +
geom_histogram(aes(x = created_at, fill = is_fake_news ))  +
scale_x_datetime(breaks=date_breaks('2 months'), labels = date_format("%b"))
data_extended <-
data %>%
mutate(tweet_text_exclamations = str_count(text, "!")) %>%
mutate(tweet_text_caps = str_count(text, "[A-Z]")) %>%
mutate(tweet_text_digits = str_count(text, "[0-9]")) %>%
mutate(tweet_text_emojis = str_count(text, '[\U{1F300}-\U{1F6FF}]')) %>%
mutate(tweet_text_emoji_flag = str_count(text, '\U{1F1FA}|\U{1F1F8}]'))
ggplot(data_extended) +
geom_density(aes(x=tweet_text_emojis, color=is_fake_news, fill=is_fake_news), alpha = 0.5)  +
scale_x_continuous(trans="log10")
ggplot(data_extended) +
geom_density(aes(x=user_followers_count, color=is_fake_news, fill=is_fake_news), alpha = 0.5)  +
scale_x_continuous(trans="log10")
correlation_table(data_extended, target='is_fake_news')
library(caret)
data_classification <-
data_extended %>%
mutate(is_fake_news = as.factor(ifelse(is_fake_news, 'Yes', 'No'))) %>%
select(-one_of('tweet_id', 'created_at', 'text', 'user_screen_name'))
rpartCtrl <- trainControl(classProbs = TRUE) # añadir: method = "cv", number = 10
rpartParametersGrid <- expand.grid(.cp = c(0.01, 0.05))
set.seed(0)
trainIndex <- createDataPartition(data_classification$is_fake_news, p = .7, list = FALSE)
train <- data_classification[trainIndex, ]
val   <- data_classification[-trainIndex, ]
library(caret)
data_classification <-
data_extended %>%
mutate(is_fake_news = as.factor(ifelse(is_fake_news, 'Yes', 'No'))) %>%
select(-one_of('tweet_id', 'created_at', 'text', 'user_screen_name'))
library(caret)
data_classification <-
data_extended %>%
mutate(is_fake_news = as.factor(ifelse(is_fake_news, 'Yes', 'No'))) %>%
select(-one_of('tweet_id', 'created_at', 'text', 'user_screen_name'))
rpartCtrl <- trainControl(classProbs = TRUE) # añadir: method = "cv", number = 10
rpartParametersGrid <- expand.grid(.cp = c(0.01, 0.05))
set.seed(0)
trainIndex <- createDataPartition(data_classification$is_fake_news, p = .7, list = FALSE)
train <- data_classification[trainIndex, ]
val   <- data_classification[-trainIndex, ]
rpartModel <- train(is_fake_news ~ .,
data = train,
method = "rpart",
metric = "Accuracy",
trControl = rpartCtrl,
tuneGrid = rpartParametersGrid)
rpartModel
rpartModel$finalModel
library(rpart.plot)
rpart.plot(rpartModel$finalModel)
library(tidyverse)
library(readxl)
data_raw <- read_excel('twitter_fakenews_USElections_2016.xlsx', sheet = 1, na = c('UNKNOWN'))
data_raw
library(tidyverse)
library(readxl)
data_raw <- read_excel('twitter_fakenews_USElections_2016.xlsx', sheet = 1, na = c('UNKNOWN'))
data_raw
library(tidyverse)
library(readxl)
data_raw <- read_excel('twitter_fakenews_USElections_2016.xlsx', sheet = 1, na = c('UNKNOWN'))
data_raw
library(tidyverse)
library(readxl)
data_raw <- read_excel('twitter_fakenews_USElections_2016.xlsx', sheet = 1, na = c('UNKNOWN'))
data_raw
Sys.setlocale("LC_ALL","C")  # Locale for date format
data_raw$created_at <- as.POSIXct(data_raw$created_at, tz="GMT", format="%a %b %d %H:%M:%S +0000 %Y")
data_raw
library(tidyverse)
library(readxl)
data_raw <- read_excel('twitter_fakenews_USElections_2016.xlsx', sheet = 1, na = c('UNKNOWN'))
data_raw
library(tidyverse)
library(readxl)
data_raw <- read_excel('twitter_fakenews_USElections_2016.xlsx', sheet = 1, na = c('UNKNOWN'))
data_raw
library(tidyverse)
library(readxl)
data_raw <- read_excel('twitter_fakenews_USElections_2016.xlsx', sheet = 1, na = c('UNKNOWN'))
data_raw
knitr::opts_chunk$set(message = FALSE)
library(knitr)
library(tidyverse)
library(funModeling)
library(DataExplorer)
training_data_raw <- read_csv("data/training.csv")
training_data_raw
test_data_raw <- read_csv("data/test.csv")
test_data_raw <- read_csv("data/test.csv")
test_data_raw
training_data <- training_data_raw %>%
na_if(-999.0)
training_data <- training_data_raw %>%
na_if(-999.0)
training_data
# glimpse(training_data)
summary(training_data)
glimpse(training_data)
summary(training_data)
summary(training_data)
knitr::opts_chunk$set(message = FALSE)
library(knitr)
library(tidyverse)
library(funModeling)
library(DataExplorer)
if(!file.exists("data/training.csv")) {
library(httr)
url <- "http://sl.ugr.es/higgs_sige"
GET(url, write_disk(temp <- tempfile(fileext = ".zip")))
unzip(temp, exdir = "data")
unlink(temp)
}
training_data_raw <- read_csv("data/training.csv")
training_data_raw
test_data_raw <- read_csv("data/test.csv")
training_data <- training_data_raw %>%
na_if(-999.0)
# glimpse(training_data)
summary(training_data)
df_status(training_data)
summary(training_data)
df_status(training_data)
table(training_data$Label)
table(training_data$Label)
table(training_data$DER_mass_MMC)
table(training_data$Label)
ggplot(training_data) +
geom_histogram(aes(x = Label, fill = as.factor(Label)), stat = "count") +
labs(x = "", y = "") +
scale_fill_discrete(name ="Clase", labels=c("(b)ackground", "higg(s)"))
